\iffalse
\bibliography{reference/refs}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                 %
%                            CHAPTER ONE                          %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{chap:intro}

Suppose in a social experiment, the designers expect to observe people's
reactions when strangers ask for a help to them. The experiment results are 
recorded as images and videos. To express the research output to public,
the recorded data is required to be shown. In this case, the privacy of 
participants in images or videos must be well protected. Meanwhile, the
data should still have the ability to describe the expected research output.

We concentrate on protecting privacy by de-identifying face regions in images and
videos. In this chapter, we describe the current research works on face 
de-identification and the challenges in section \ref{sec:bg}, then give out
a summary about our approaches in section \ref{sec:approach}, then list
the contributions in section \ref{sec:contri}, at last demonstrate the thesis
outline in section \ref{sec:outline}. 

\section{Background}
\label{sec:bg}
With the development of camera technologies, the image and video acquisition
is becoming easier. Nowadays, mounts of applications are centered around image
data. Surveillance videos are covering more and more places due to the wide 
deployment of camera devices. On the other aspect, the advances of computing
hardwares and computer vision algorithms make it almost effortless to collect, 
store and analyze massive image and video data. The best face recognition 
algorithms, like FaceNet \cite{facenet15}, DeepFace \cite{deepface14}, can 
achive more than $95\%$ accuracy in $LFW$ and Youtube video datasets. It
means that the current machine recognizer perfoms well and stably regardless
of the complex background, variant illuminations and unknown face poses. A
recent research indicates that it is possible to infer personal informations 
from a single face image \cite{FRandNetwork14}. Therefore, privacy protection
rises as an important problem during the sharing of image and video data. 
With the purpose of protecting privacy, images and videos with people visible 
in the scene are prohibited to be shared in some applications. For example,
in Google Streetview Service which offers high quality street view images,
the faces of people in the scene are blurred in the service website currently.
Another proper example is a surveillance system monitoring patients in nursing 
home \cite{nursing06}. The identity of patients in the surveillance video has 
to be removed before sharing. Since the face is one of the most significant 
biometric features for a person, our research focuses on protecting the privacy 
in images and videos through face de-identification, which aims at removing
identity information from faces.

Different challenges exist in face de-identification for images and videos. For 
images, multiple types of information could be extracted from one face image, such as
identity, expression, skin color, gender, age, etc. Among of them, only identity
information is related to privacy. The other types of information are defined
as data utility of a face image. The key point of face de-identification is to
keep the balance between privacy protection and data utility preservation. For
instance, the expression information must be preserved in the images from a medical 
face database aiming at demonstrate the painful faces \cite{mediDB09}. For videos,
one more point is required in face de-identification. As a set of continuous
images, a video is de-identified frame by frame separately. Thus the identity
of all frames after processing should not change among adjacent frames. 
This would disturb the audiences during the video playback. To summarize,
there are two challenges in face de-identification for images and videos:
\begin{enumerate}
	\item Keeping the balance between privacy protection and data utility 
		  preservation for images and videos.
	\item Keeping the de-identified identity invariant for videos.
\end{enumerate}

To overcome the challenges, plenty of related research works have been released. 
The most common method is obfuscating images such as pixelization or blurring 
\cite{Boyle00,Agrawal09}. Because of the simple implementation, the image 
obfuscation method is suitable not only to images, but also to videos, such 
as TV interviews. However, in this approach, the face regions are unreadable 
to humans after obfuscation. Only replacing the 
face region with another natural face could preserve the non-privacy related 
information while removing privacy information. A formal de-identification
algorithm, $k$-same framework, is then proposed \cite{Newton05,Ralph05,Gross08}. 
The algorithm takes the average of $k$ closest faces as the de-identified result. 
As a consequence, the $k$-same framework is only workable to the person specific 
database, in which each person has just one image. Other formal algorithms, such 
as face swapping, face synthetic from multiple persons, fail to address the 
problem of presreving data utilities \cite{swap08,Mosa14}. Except for the
obfuscation methods, all the formal approaches are not suitable to face
de-identification in videos. Therefore, we try to extent the processing 
algorithms to larger databases and videos. 

\section{Summary of Proposed Approaches}
\label{sec:approach}
We use the active appearance model (AAM) \cite{AAM01,Matthews_04} and higher order 
tensors analysis to de-identify the faces in images and videos. The AAM projects
a face image into a vector space and represents it with a set of coefficients.
The model representation helps avoid ghost faces \cite{Gross08}. Considering
the balance between privacy and data utility, we wish to decompose a face image
into multiple dimensions so that only the privacy related factors are altered. 
Therefore, we build up a higher-order tensor and analyze it. 
Tensor analysis, also known as multilinear algebra, makes the assumption that 
images are formed as the result of multiple factors. Furthermore, these factors 
are amenable to linear analysis as each factor is allowed to vary in turn, while 
the remaining factors are held constant \cite{Vasi02,VasilescuT03}.

For images, the face de-identification algorithm is proposed based on the tensor 
CANDECOMP/PARAFAC(CP) decomposition \cite{Lathauwer_rank,Kolda09}. We construct 
a tensor using multiple types of images, then 
project a new input one into this tensor. After representing the input image by 
identity and other types of parameters, we can pick out the identity factor and 
fuse it with other identity parameters from different persons. At last, we de-identify 
a face image by reconstructing it with altered identity parameters and its 
untouched parameters. The advantage of our tensor-based algorithm is that the 
de-identification process could focus only on privacy related information so that 
the other $data$ $utilities$ could be well preserved. 

Among kinds of tensor decomposition algorithms, the CP decomposition estimates
the parameters for each dimension using Alternating Least Square (ALS) method.
In this way, any face images could be decomposed properly. However, it is not
suitable to face de-identification in videos. The reason is that the CP
decomposition is sensitive to initial values and would produce different
values due to different initial guesses. For videos, AAM is used to represent
face images and the Higher-order Singular 
Value Decomposition(HOSVD) \cite{Lathauwer00} is used to decompose one frame 
into multiple dimensions. One set of them is privacy related, called the 
$identity$ factors, and the others are non-privacy related factors 
\cite{Feng12,TPAMI09}. With the basis subtensors in HOSVD, this approach 
produces the same computation results for every computation. 
During the video de-identification, one frame in the 
video is picked out and its identity factors are altered to produce a set of 
de-identified identity factors. For all the other frames in the video, each 
of them is reconstructed by only replacing the privacy related factors with 
the de-identified identity ones. Therefore, the identity of de-identified 
result could keep constant.

\section{Contributions}
\label{sec:contri}
In this thesis, we have done some work on face de-identification in images
and videos. Our work contributes on three aspects:
\begin{enumerate}
	\item We use tensor analysis in face de-identification. By decomposing
		the face regions into privacy related factors and other non-privacy related 
		factors, the proposed algorithms could focus on removing privacy 
		information so that all the other factors are leaved untouched. Therefore, our approach
		is suitable to the datasets with multiple factors, such as {\it 
		expressions, poses, illuminations,} etc. Furthermore, each person in
		the dataset could have more than one image.
	\item In image processing, our algorithm is workable to the images not 
		involving in the tensor. The tensor CP decomposition is used to process images. 
		Since the parameters for each dimension is estimated by initial guess using ALS,
		the CP decomposition algorithm enlarges the representation ability for face
		images. We also firstly use	rank-$n$ approximation.
		The increasement of value $n$ helps the face representation more precise, especially
		for the images never appear in tensors. 
	\item We succeed to extend the face de-identification algorithms to videos. The existing
		methods add obfuscations to the regions related to privacy. Compared to the
		priveous algorithms, the proposed one has two advantages. 
		Firstly, our algorithm produces natural de-identified results from videos. 
		Because the non-privacy related factors are untouched during de-identification, 
		the results could keep the data utility such as {\it expressions, skin colors,} etc. 
		in a face. Secondly, our method could de-identify a series of images and keep 
		the resulting identity invariant throughout the video playback.
\end{enumerate}

\section{Thesis Outline}
\label{sec:outline}
In this thesis, we develope a framework to remove privacy related factors and 
preserve other data utility factors in images and videos. 
The rest of this thesis is structured as following.
In Chapter \ref{chap:relatedWorks}, we demonstrate the previous research works
on face de-identification in images and videos individually. Chapter \ref{chap:foundamental}
introduces foundamental theories of the proposed algorithm: tensor
analysis and Active Appearance Model. In Chapter \ref{chap:FDimages} and 
Chapter \ref{chap:FDvideos}, the face de-identification in images and videos are 
explained separately. Chapter \ref{chap:conclusions} expresses the summary of our
works and give out conclusions.

